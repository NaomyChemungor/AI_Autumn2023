{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaomyChemungor/AI_Autumn2023/blob/main/AI_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kxldJwrSh0ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuFH3SCrXJT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775b8440-fa11-4137-a473-33cbe28df798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# train_images = X_train\n",
        "# train_labels = y_train\n",
        "# test_images = X_test\n",
        "# test_labels = y_test\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values to the range [0, 1]\n",
        "#X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# Normalize the pixel values to the range -1 to 1\n",
        "X_train = (X_train.astype(np.float32) / 127.5) - 1.0\n",
        "X_test = (X_test.astype(np.float32) / 127.5) - 1.0"
      ],
      "metadata": {
        "id": "Q3Xp3tznkHTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(type(X_train))\n",
        "# a single image array (28x28):\n",
        "print(X_train[0].shape)\n",
        "#print(X_train[0])"
      ],
      "metadata": {
        "id": "pR2GB5WQXbD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a0b920-a0f1-4540-a16d-5fa63d594d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "<class 'numpy.ndarray'>\n",
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cv2 import resize\n",
        "\n",
        "# Loop through the images, resize them to 16x16\n",
        "\n",
        "X_train_res16 = []\n",
        "for image in X_train:\n",
        "    resized_image = resize(image, (16, 16))\n",
        "    X_train_res16.append(resized_image)\n",
        "X_train_res16 = np.array(X_train_res16)\n",
        "\n",
        "X_test_res16 = []\n",
        "for image in X_test:\n",
        "    resized_image = resize(image, (16, 16))\n",
        "    X_test_res16.append(resized_image)\n",
        "X_test_res16 = np.array(X_test_res16)\n",
        "\n",
        "print(X_train_res16.shape)\n",
        "print(X_test_res16.shape)"
      ],
      "metadata": {
        "id": "8EP-T4QFihFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6af745-aa79-40fa-ffa5-3541fa240937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 16, 16)\n",
            "(10000, 16, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values to the range [0, 1]\n",
        "#X_train_res16, X_test_res16 = X_train_res16 / 255.0, X_test_res16 / 255.0\n",
        "\n",
        "print(X_train_res16[0])"
      ],
      "metadata": {
        "id": "9GO_IHQPTdhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and display the selected image\n",
        "def display_dig_img(image):\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(image, cmap='gray')  # Display the image in grayscale\n",
        "  plt.title(f\"Labelled as {y_train[image_index]}\")\n",
        "  #plt.axis('off')  # Hide axis labels\n",
        "  plt.show()\n",
        "\n",
        "display_dig_img(X_train[0])\n",
        "display_dig_img(X_train_res16[0])\n",
        "display_dig_img(X_train[1])\n",
        "display_dig_img(X_train_res16[1])"
      ],
      "metadata": {
        "id": "4P24Lhzxhb2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the original images\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "print(X_train_flat.shape)\n",
        "print(X_test_flat.shape)\n",
        "#print(X_train_flat[0])"
      ],
      "metadata": {
        "id": "bU4y09R2nY22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5101b646-40d4-473f-f947-0e092d2b017e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the resized images\n",
        "X_train_res16_flat = X_train_res16.reshape(X_train_res16.shape[0], -1)\n",
        "X_test_res16_flat = X_test_res16.reshape(X_test_res16.shape[0], -1)\n",
        "print(X_train_res16_flat.shape)\n",
        "print(X_test_res16_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm4UDmwFzJrp",
        "outputId": "5cded6fc-c7aa-459b-c947-bb55fe649f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 256)\n",
            "(10000, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "dw6ZMQYbp2jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding - needed for NN\n",
        "print(y_train[0])\n",
        "y_train_ohe = to_categorical(y_train, 10)\n",
        "y_test_ohe = to_categorical(y_test, 10)\n",
        "print(y_train_ohe[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAMMcbPQ0u1E",
        "outputId": "f219c4a1-5bca-4e31-ef7b-42c119e96293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def init_weights2(input_pixels):\n",
        "  # rand - random samples from a uniform distribution over [0, 1)\n",
        "  weights = np.random.rand(input_pixels, 10) # input_features x output neurons\n",
        "  return weights\n",
        "'''\n",
        "\n",
        "# to be used for the hidden layer(s)\n",
        "def relu(x):\n",
        "  return max(0, x)\n",
        "\n",
        "# He initialization https://doi.org/10.48550/arXiv.1502.01852\n",
        "def init_weights_he(input_pixels):\n",
        "  # Calculate the standard deviation based on the formula\n",
        "  std_dev = np.sqrt(2 / input_pixels)\n",
        "\n",
        "  # Generate random numbers with a normal distribution\n",
        "  weights = np.random.normal(loc=0.0, scale=std_dev, size=(input_pixels, 10))\n",
        "\n",
        "  # Verify the mean and standard deviation of the generated numbers\n",
        "  mean_generated = np.mean(weights)\n",
        "  std_dev_generated = np.std(weights)\n",
        "  print(\"He Distribution Mean:\", mean_generated)\n",
        "  print(\"He Distribution Standard Deviation:\", std_dev_generated)\n",
        "  return weights\n",
        "\n",
        " # to be used for the output layer - will return an array of probabilities where each element represents the probability of a class. The sum of all probabilities will be equal to 1\n",
        "def softmax(logits):\n",
        "    exp_logits = np.exp(logits)\n",
        "    sum_exp_logits = np.sum(exp_logits)\n",
        "    probabilities = exp_logits / sum_exp_logits\n",
        "    return probabilities\n",
        "\n",
        "# to be used with Sigmoid, Tanh and Sigmoid activation\n",
        "# Xavier Glorot initialization\n",
        "# Uniform Xavier Init\n",
        "def init_weights_xavier(input_neurons, output_neurons):\n",
        "\n",
        "    # Calculate the range for random initialization\n",
        "    limit = np.sqrt(6 / (input_neurons + output_neurons))\n",
        "\n",
        "    # Generate random weights within the specified range\n",
        "    weights = np.random.uniform(-limit, limit, size=(input_neurons, output_neurons))\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "\n",
        "biases = np.zeros(10)  # 1 bias for each output neuron\n",
        "\n",
        "weights = init_weights_xavier(256, 10)\n",
        "#print(f'Weights: \\n{weights}')\n",
        "#print(f'Biases: \\n{biases}')\n",
        "#print(f'Image: \\n{X_train_res16_flat[0]}')\n",
        "logits = np.dot(X_train_res16_flat[0], weights)+biases\n",
        "#result = np.vectorize(relu)(result)  # <=> result = np.maximum(0, result)\n",
        "probabilities = softmax(logits)\n",
        "print(probabilities)\n",
        "print(f'Weights: \\n{weights}')\n",
        "#print(f'Image: \\n{X_train_res16_flat[0]}')\n",
        "#     a = ReLU(np.dot(weights, a)+biases)\n"
      ],
      "metadata": {
        "id": "xU7-HKXPjhQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b195d2-83e4-4d00-da22-70a0ccab40fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07307658 0.03940128 0.03211859 0.11124146 0.08602388 0.11608614\n",
            " 0.02672221 0.00899859 0.14825798 0.35807327]\n",
            "Weights: \n",
            "[[ 0.11809604 -0.07536606  0.0487328  ... -0.04017134  0.1034798\n",
            "  -0.14227073]\n",
            " [ 0.0572398   0.00298411  0.01437207 ... -0.00034737 -0.0155599\n",
            "  -0.05428124]\n",
            " [ 0.14640005  0.00451404 -0.1064044  ... -0.12900311  0.14041516\n",
            "   0.09122092]\n",
            " ...\n",
            " [ 0.14707373  0.06598979  0.05357578 ...  0.08073634  0.01117372\n",
            "   0.03800768]\n",
            " [ 0.06136872  0.11943084 -0.06443906 ...  0.11491055 -0.13510033\n",
            "   0.01113681]\n",
            " [ 0.13399497 -0.05511553  0.02872037 ... -0.13953735 -0.05870323\n",
            "   0.07365326]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a simple feedforward Neural Network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "#    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "model.fit(X_train, y_train_ohe, epochs=5)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_ohe)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9l3TTjdaHJG",
        "outputId": "1e6078a4-cb39-4dbb-cdb5-234655a75adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3022 - accuracy: 0.9143\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1435 - accuracy: 0.9588\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1051 - accuracy: 0.9693\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0835 - accuracy: 0.9747\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0696 - accuracy: 0.9790\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9747\n",
            "Test accuracy: 0.9746999740600586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple feedforward neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(16, 16)),\n",
        "#    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "model.fit(X_train_res16, y_train_ohe, epochs=5)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss2, test_accuracy2 = model.evaluate(X_test_res16, y_test_ohe)\n",
        "print(f\"Test accuracy: {test_accuracy2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c8166e-d18b-4769-b2ea-31bbc5c4bf32",
        "id": "Q5jXVZt20e1m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3943 - accuracy: 0.8930\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1985 - accuracy: 0.9430\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1505 - accuracy: 0.9566\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1223 - accuracy: 0.9645\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1039 - accuracy: 0.9697\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9688\n",
            "Test accuracy: 0.9688000082969666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Flatten the images\n",
        "x_train = x_train.reshape(-1, 28 * 28)\n",
        "x_test = x_test.reshape(-1, 28 * 28)\n",
        "\n",
        "# Number of clusters (fuzzy sets)\n",
        "num_clusters = 10\n",
        "\n",
        "# Perform k-means clustering to generate fuzzy sets\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
        "kmeans.fit(x_train)\n",
        "\n",
        "# Generate fuzzy membership values based on distance to cluster centers\n",
        "fuzzy_memberships = kmeans.transform(x_train)\n",
        "\n",
        "# Create fuzzy rules\n",
        "def create_fuzzy_rules(memberships):\n",
        "    rules = []\n",
        "    for sample in memberships:\n",
        "        rule = np.argmax(sample)  # Select the cluster with the highest membership\n",
        "        rules.append(rule)\n",
        "    return np.array(rules)\n",
        "\n",
        "fuzzy_rules = create_fuzzy_rules(fuzzy_memberships)\n",
        "\n",
        "# Make predictions using fuzzy rules\n",
        "def fuzzy_predict(fuzzy_rules, memberships):\n",
        "    predictions = []\n",
        "    for i in range(len(fuzzy_rules)):\n",
        "        predictions.append(np.argmax(memberships[i] == fuzzy_rules[i]))\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Apply fuzzy logic classifier to the test data\n",
        "test_fuzzy_memberships = kmeans.transform(x_test)\n",
        "y_pred = fuzzy_predict(fuzzy_rules, test_fuzzy_memberships)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "0Ov4FDAz30Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN #Naomy\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def knn_predict(X_train, y_train, X_test, k):\n",
        "    num_test = X_test.shape[0]\n",
        "    y_pred = np.zeros(num_test, dtype=int)\n",
        "\n",
        "    for i in range(num_test):\n",
        "        distances = np.sqrt(np.sum((X_train - X_test[i])**2, axis=1))\n",
        "        nearest_indices = np.argsort(distances)[:k]\n",
        "        nearest_labels = y_train[nearest_indices]\n",
        "        y_pred[i] = np.argmax(np.bincount(nearest_labels))\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Load the MNIST dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Make predictions using KNN\n",
        "k = 5  # Number of neighbors\n",
        "y_pred = knn_predict(X_train, y_train, X_test, k)\n",
        "\n",
        "# Calculate the accuracy of the KNN classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "0CBgN6WrZt9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665c53f2-1b9f-4ad9-e056-ed34b466933a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9861111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN1\n",
        "input_features = 256 # 256 features -> X_train_res16_flat\n",
        "weights = np.random.rand(input_features,output_features) # random samples from a uniform distribution over [0, 1)\n"
      ],
      "metadata": {
        "id": "XZkgXoclnt-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}